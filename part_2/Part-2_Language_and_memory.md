# Part 2. Language and memory parts

## Language: recursion

There are many types of language. There are natural languages, like English or British Sign Language, and formal languages, like algebra and aithmetic. All these languages have a primary form of expression, like speech, using the mouth, nose, tongue, lips and the vocal folds (which is probably the most complex or sophisticated form of expression), gestures and writing, and secondary, derived, forms.

Computers imitate humans and like humans they can interpret language. There are two distinctions, though: humans aren't instructed to learn a language and, not incidentally, computers use formal languages, not natural languages.
Natural languages, as opposed to formal languages, are, or appear to be, so complex that we can't formalise them: we can't describe in a logical manner the rules that govern such languages. There are written grammars, but none of these accounts for all the expressions that you'll find in a natural language.

Formal languages are logical and governed by rules we can agree on. Grammars of formal languages can be used to know with certainty whether a certain language construct, a phrase, to use the parlance of natural languages, is part of the language (or could be, depending on your conception of language).

But most languages, and most probably all, used by humans, including arithmetic and algebra, have one important thing in common: they use recursion, abstractions (based on combinations of parts) and they require a memory where abstractions are formless, structureless. Machines also have a language of their own (quite a few, actually, but nothing compared to the roughly 5000 natural languages), but that language uses structures, form, representations, to mimic abstractions.

Another secondary representation of language is mental. Even though meaning, the semantics, not the syntax, which is part of a language, is very much a product of the mind and used by the mind, the structure, the form, which are integral parts of a language, seem to be derived from the spoken form when represented, imagined, in the mind.

When doing mental arithmetic, you keep partial results in your working memory. These partial results could just have been the final result of a calculation. You apply a method to one part of the calculation (maybe you have first divided one complex and undivided part into two or more parts) and you take the result and make it part of another, similar, calculation. You could write down all the steps as part of one calculation.

That makes a language recursive: you apply the same method to the whole as you do to its (logical, most coherent) parts. Most formal languages use recursion and (almost certainly) all natural languages use it. But computers can't readily understand it. They prefer language that is more like that found in a cookbook: a simple recipe.
And a computer works much like that: you don't have to remember the result of a step after you've done it, but you only have to read the next steps. Any state is represented by the state your food is in and requires no use of working memory beyond knowing at which step you are.

You can easily "use up" all working memory when doing mental arithmetic, because you do have to keep all intermediate results in memory. Since you're dealing with abstractions, numbers and operators, not just the state of your kitchen, we (or our ancestors) invented writing systems, written scripts. Computers aren't like kitchens, exactly. All they represent are values, like numbers. Lots of values and coordinates, called addresses, to find the right one and the structure them into something more meaningful to us.

They represent these values, the state of the machine at one moment in time, in some kind of working memory. But they use similar types of memory to store the state of many virtual computers, much like we do with writing: when we read, our state of mind changes and we focus on something else than before. That's pretty much how computers do things. They divide memory into small pockets of state and focus on one of these parts at any one time.

While computers can't make dinner, a hob, the top of a stove, with rings, burners, is a bit like those two kinds of memory (the working memory and what we call primary storage, much like a huge notebook or scratchpad) work.

Assume we have a hob with four rings, four burners. There are four switches, one for each ring, and the rings can either be turned on or off, heating them up or not. The switches are binary and the state that each ring can be in is equally binary.
The different configurations of our hub is 2 to the power of 4, or two (heating up or not) times two times two timess two. Two to the power of 4 is 16 different states of our hob.

Computer memory (and all other computer logic, memory connected in different ways and their interaction) works with such binary states and switches. The difference with the hob is that different states cause different states because each such basic part, something that can be heating up or not (conducting energy or not), is also a switch for another such part. Each (semiconductor) part is interacting with other parts. Intricate connections using these parts is what makes the computer function, while simpler configurations, where there is very little to no interaction, is used to store and retrieve data, like a piece of paper to write down intermediate steps and results of calculations.

As mentioned earlier and a more accurate but more complicated example, what those types of memory, and the logic, intricate configurations of parts, are made of is not very different from how neurons work in the brain, only simplified (simply because we have no idea how the brain works, really). Another difference is that our brains change: the connections between the basic units of the brain that can be in different, relatively stable, states and that change the state of other such parts like a switch, the neurons, change constantly.

## Memory: divisions

The most basic unit of memory is called the bit. It's what the binary switches represent. The state of one bit can also be represented as a 0 or a 1. Four bits together can represent 16 different states and though we could use four numerals to represent those states (each either 1 or 0), we'd better make use of all the other numbers and characters, different types of tokens, meaningful units, we use in our writing systems to represent those 16 states more practically. Let's say we use all the 10 decimal numbers and the letters a to f.
If we add a bit to the mix, we end up with 32 states and we could include the tokens, the characters, g to v. This representation is never used. The main reason is that the type of computer used most often today uses at the very least 8 bits at a time. That gives us 256 different states, different values, and we don't have enough "normal" characters to represent all those states. 8 also isn't divisible by 5, so we can't use the numerals-and-most-of-the-alphabet character set. We could combine that character set with the one used for 16 states, 4 bits, but it would be difficult to read. That's why we use 2 characters, each able to represent 16 states, using the numerals-and-a-to-f set. We call this notation hexadecimal notation (hexa- meaning 6 and decimal 10; also called base 16, cf. base 10 for decimal number notation) and the tokens used hexadecimals.

The smallest meaningful unit of bits a computer can work with is called a byte. Most if not all computers that we use today use a byte size of 8 bits.

The largest value a computer can interpret (without having to use extra memory, much like writing on a piece of paper when doing arithmetic; it's logically, meaningfully, indivisible when used as one value) is, for most computers, 64. The coordinates, the address, used to reference other parts of the memory space (all the bits, binary switches pretty much in one row, as far as the computer is concerned; this includes all types of storage, but sometimes only parts of it: more on that later), sometimes called a pointer, is 64 bits in size (on most computers). This pointer or address size is called a word.

Because a word used to be smaller, 16 bits and later 32 bits, the unit is sometimes referred to as a quad word (quad meaning 4; four times 16 bits), the 32 bit unit as a double word and the 16 bit unit as a word. The main reason for this is that older software written in languages used on machines with 16 bit words used the name word for 16 bits and it would've required a lot of (technically needless) rewriting to update the software language code (or source code).

The next, bigger unit, containing a mix of 64, 32, 16 and 8 bit values (as far as the primary, main, storage is concerned; this is different for file systems used to subdivide secondary storage, the, less changeable, storage used when there is no primary storage left), is the page. A page, on most computers, has a size of 4096 bytes. All data in a page is structured, subdivided: it's highly unlikely there is a program that interprets 4096 bytes as one value (and it would require a lot of extra memory to do the calculations, while calculations done on words can be done without using extra memory). But a row of characters, each 8 bits in size, could be a page long. 12 bits are needed to store an address of, a pointer to, a byte in a page.

The other bits in a word (52 bits) that is used as a pointer, are used multiple times. A computer focuses on one byte, 16 bits, 32 bits or 64 bits at a time, but the context of that piece of data, the other data used together with that data to do something useful, is also in a privileged state: it can use all the 52 bits (or less if there isn't enough storage space anywhere, not just in primary storage) and the computer will translate the 52 bits into an address that spans all data in primary storage and much of the data in secondary storage (like a disk drive; less changeable, often much bigger and often slower storage). If the computer needs to read something that is in secondary storage, it will transfer all the data on the page the requested data is in, into primary storage (the assumption is that if you want something in a particular page, you probably want more data that's contained in it).

The address translation done by the computer serves an important purpose, which was briefly mentioned: a computer program shouldn't be able to refer to data that is outside the context of the program. Each program has a limited number of pages it can use and it isn't able to refer to any data in pages other than its own. In software development parlance, a computer program is called a process. Each process runs in its own virtual "address space": each can only refer to data it "owns" (with some notable exceptions which will be discussed later). A computer shifts focus from one context to another, from one process to the next, one word to the next. This continuous switching focus is what is called, not just when talking about computers, multitasking. And unlike humans, computers are good at it.

The next, bigger, unit of data is not of any fixed size, but is determined by the amount of memory available in primary storage and in secondary storage. Secondary storage is (or better be) bigger and slower than primary storage. A hard disk is a type of secondary storage. Many newer computers, including smartphones, now use much faster secondary storage which is pretty much the same as the primary storage used today. But just because there's a bigger address space, more memory, it's still slower than, the smaller, primary storage.


